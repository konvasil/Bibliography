
@article{he_developing_2015,
	title = {Developing {A} {Physical} {Gesture} {Acquisition} {System} {For} {Guqin} {Performance}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	url = {https://zenodo.org/record/1179088},
	doi = {10.5281/ZENODO.1179088},
	abstract = {Motion- based musical interfaces are ubiquitous. With the plethora of sensing solutions and the possibility of developing custom designs, it is important that the new musical interface has the capability to perform any number of tasks. This paper presents the theoretical framework for defining, designing, and evaluation process of a physical gesture acquisition for Guqin performance. The framework is based on an iterative design process, and draws upon the knowledge in Guqin performance to develop a system to determine the interaction between a Guqin player and the computer. This paper emphasizes the definition, conception, and evaluation of the acquisition system.},
	urldate = {2024-02-19},
	author = {He, Jingyin and Kapur, Ajay and Carnegie, Dale},
	month = jun,
	year = {2015},
	note = {Publisher: Zenodo},
}

@article{ho_slowqin_2019,
	title = {The {SlowQin}: {An} {Interdisciplinary} {Approach} to reinventing the {Guqin}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {The {SlowQin}},
	url = {https://zenodo.org/record/3672948},
	doi = {10.5281/ZENODO.3672948},
	abstract = {This paper presents an ongoing process of examining and reinventing the Guqin, to forge a contemporary engagement with this unique traditional Chinese string instrument. The SlowQin is both a hybrid resemblance of the Guqin and a fully functioning wireless interface to interact with computer software. It has been developed and performed during the last decade. Instead of aiming for virtuosic perfection of playing the instrument, SlowQin emphasizes the openness for continuously rethinking and reinventing the Guqin's possibilities. Through a combination of conceptual work and practical production, Echo Ho's SlowQin project works as an experimental twist on Historically Informed Performance, with the motivation of conveying artistic gestures that tackle philosophical, ideological, and socio-political subjects embedded in our living environment in globalised conditions. In particular, this paper touches the history of the Guqin, gives an overview of the technical design concepts of the instrument, and discusses the aesthetical approaches of the SlowQin performances that have been realised so far.},
	urldate = {2024-02-19},
	author = {Ho, Echo and de Campo, Prof. Dr. Phil. Alberto and Hoelzl, Hannes},
	month = jun,
	year = {2019},
	note = {Publisher: Zenodo},
}

@book{rees_lives_2009,
	address = {Urbana},
	title = {Lives in {Chinese} music},
	isbn = {978-0-252-09225-1},
	abstract = {Until recently, most scholarly work on Chinese music in both Chinese and Western languages has focused on genres, musical structure, and general history and concepts, rather than on the musicians themselves. This volume breaks new ground by focusing on individual musicians active in different amateur and professional music scenes in mainland China, Hong Kong, and Chinese communities in Europe. Using biography to deepen understanding of Chinese music, contributors present richly contextualized portraits of rural folk singers, urban opera singers, literati, and musicians on both geographic and cultural frontiers. The topics investigated by these authors provide fresh insights into issues such as the urban-rural divide, the position of ethnic minorities within the People's Republic of China, the adaptation of performing arts to modernizing trends of the twentieth century, and the use of the arts for propaganda and commercial purposes. The social and political history of China serves as a backdrop to these discussions of music and culture, as the lives chronicled here illuminate experiences from the pre-Communist period through the Cultural Revolution to the present. Showcasing multiple facets of Chinese musical life, this collection is especially effective in taking advantage of the liberalization of mainland China that has permitted researchers to work closely with artists and to discuss the interactions of life and local and national histories in musicians' experiences},
	language = {eng},
	publisher = {University of Illinois Press},
	author = {Rees, Helen},
	year = {2009},
	note = {OCLC: 811409120},
}

@book{hermann_sonification_2011,
	address = {Berlin},
	title = {The sonification handbook},
	isbn = {978-3-8325-2819-5},
	publisher = {Logos Verlag},
	editor = {Hermann, Thomas and Hunt, Andy and Neuhoff, John G.},
	year = {2011},
	note = {OCLC: ocn771999159},
	keywords = {Auditory perception, Computer sound processing, Psychoacoustics, Recording and reproducing Digital techniques, Sound},
}

@inproceedings{christopher_kontrol_2013,
	title = {Kontrol: {Hand} {Gesture} {Recognition} for {Music} and {Dance} {Interaction}},
	abstract = {This paper describes Kontrol, a new hand interface that extends the intuitive control of electronic music to traditional instrumentalist and dancers. The goal of the authors has been to provide users with a device that is capable of detecting the highly intricate and expressive gestures of the master performer, in order for that information to be interpreted and used for control of electronic music. This paper discusses related devices, the architecture of Kontrol, its potential as a gesture recognition device, and several performance applications.},
	language = {en},
	booktitle = {New {Interfaces} for {Musical} {Expression}},
	author = {Christopher, Kameron and He, Jingyin and Kapur, Raakhi Sinha and Kapur, Ajay},
	year = {2013},
	file = {Christopher et al. - Kontrol Hand Gesture Recognition for Music and Da.pdf:/Users/k.vasilakos/Zotero/storage/N8349M6L/Christopher et al. - Kontrol Hand Gesture Recognition for Music and Da.pdf:application/pdf},
}

@book{manning_electronic_2004,
	address = {Oxford},
	edition = {Rev. and expanded ed.},
	title = {Electronic and computer music},
	isbn = {978-0-19-517085-6 978-0-19-514484-0},
	language = {eng},
	publisher = {Oxford University Press},
	author = {Manning, Peter},
	year = {2004},
	annote = {Discography. - Includes bibliographical references and index. - Previous ed.: Oxford: Clarendon, 1993},
	annote = {The background, to 1945 -- Developments from 1945 to 1960 -- Paris and musique concrète -- Cologne and electronische musik -- Milan and elsewhere in Europe -- America -- New horizons in electronic design -- The voltage-controlled synthesizer -- The electronic repertory from 1960 -- Works for tape -- Live electronic music -- Rock and pop electronic music -- The digital revolution to 1980 -- The foundations of computer music -- From computer technology to musical creativity -- The microprocessor revolution -- The characteristics of digital audio -- MIDI -- The development of the MIDI communications protocol -- From analog to digital: the evolution of MIDI hardware -- From microcomputer to music computer: the MIDI dimension -- New horizons for MIDI-based technologies -- Desktop synthesis and signal processing -- Personal computers and sound processing -- Music workstations and related computing architectures -- The expanding perspective -- Performance controllers -- New horizons in synthesis and signal processing software},
}

@article{ogborn_live_2014,
	title = {Live {Coding} in a {Scalable}, {Participatory} {Laptop} {Orchestra}},
	volume = {38},
	issn = {0148-9267, 1531-5169},
	url = {https://direct.mit.edu/comj/article/38/1/17-30/94445},
	doi = {10.1162/COMJ_a_00217},
	abstract = {Live coding (Collins et al. 2003 and other articles in this special issue of Computer Music Journal) is the central performance practice of the Cybernetic Orchestra, a laptop orchestra at McMaster University in Hamilton, Ontario, Canada. Inspired by the idea of participatory culture, the ensemble has been made open to a diverse and ever changing roster of participants, and may be likened to a human laboratory exploring this question: How is live coding scalable onto larger groups of people coming from diverse backgrounds? This article presents the practices that have developed during the first three years of the Cybernetic Orchestra's existence, starting with a summary of our human organization and physical infrastructure. The EspGrid software, developed for enhanced network synchronization and sharing, is reviewed before a final section presents the live coding practices that have crystallized around this specific collective of people, equipment, and code.},
	language = {en},
	number = {1},
	urldate = {2024-03-14},
	journal = {Computer Music Journal},
	author = {Ogborn, David},
	month = mar,
	year = {2014},
	pages = {17--30},
}

@article{gresham-lancaster_aesthetics_1998,
	title = {The {Aesthetics} and {History} of the {Hub}: {The} {Effects} of {Changing} {Technology} on {Network} {Computer} {Music}},
	volume = {8},
	issn = {09611215},
	shorttitle = {The {Aesthetics} and {History} of the {Hub}},
	url = {https://www.jstor.org/stable/1513398?origin=crossref},
	doi = {10.2307/1513398},
	language = {en},
	urldate = {2024-03-14},
	journal = {Leonardo Music Journal},
	author = {Gresham-Lancaster, Scot},
	year = {1998},
	pages = {39},
	file = {Gresham-Lancaster - 1998 - The Aesthetics and History of the Hub The Effects.pdf:/Users/k.vasilakos/Zotero/storage/HVX4P2QU/Gresham-Lancaster - 1998 - The Aesthetics and History of the Hub The Effects.pdf:application/pdf},
}

@article{rohrhuber_purloined_letters_2007,
	title = {Purloined\_letters},
	language = {en},
	author = {Rohrhuber, Julian and de Campo, Alberto and Wieser, Renate and van Kampen, Jan-Kees and Ho, Echo and Hölzl, Hannes},
	year = {2007},
	file = {Rohrhuber et al. - Purloined_letters.crdownload:/Users/k.vasilakos/Zotero/storage/MHHPLN8E/Rohrhuber et al. - Purloined_letters.crdownload:application/pdf},
}

@article{wilson_free_2014,
	title = {Free as in {BEER}: {Some} {Explorations} into {Structured} {Improvisation} {Using} {Networked} {Live}-{Coding} {Systems}},
	volume = {38},
	issn = {0148-9267, 1531-5169},
	shorttitle = {Free as in {BEER}},
	url = {https://direct.mit.edu/comj/article/38/1/54-64/94446},
	doi = {10.1162/COMJ_a_00229},
	abstract = {Much improvised music that has developed since the advent of free jazz has been concerned with the imposition of structure, often through systems of directed improvisation, or through the use of rule-based approaches (e.g., game pieces). In this article, we explore the possibility of a networked live-coding system as a structural intervention mechanism par excellence, through the discussion of two pieces from the repertoire of the Birmingham Ensemble for Electroacoustic Research.},
	language = {en},
	number = {1},
	urldate = {2024-03-14},
	journal = {Computer Music Journal},
	author = {Wilson, Scott and Lorway, Norah and Coull, Rosalyn and Vasilakos, Konstantinos and Moyers, Tim},
	month = mar,
	year = {2014},
	pages = {54--64},
}

@article{bevilacqua_designing_2021,
	title = {On {Designing}, {Composing} and {Performing} {Networked} {Collective} {Interactions}},
	volume = {26},
	issn = {1355-7718, 1469-8153},
	url = {https://www.cambridge.org/core/product/identifier/S135577182100042X/type/journal_article},
	doi = {10.1017/S135577182100042X},
	abstract = {In this article, we discuss some of our research with Local Area Networks (LAN) in the context of sound installations or musical performances. Our systems, built on top of Web technologies, enable novel possibilities of collective and collaborative interaction, in particular by simplifying public access to the artwork by presenting the work through the web browser of their smartphone/tablet. Additionally, such a technical framework can be extended with so-called nano-computers, microprocessors and sensors. The infrastructure is completely agnostic as to how many clients are attached, or how they connect, which means that if the work is available in a public space, groups of friends, or even informally organised flash mobs, may engage with the work and perform the contents of the work at any time, and if available over the Internet, at any place. More than the technical details, the specific artistic directions or the supposed autonomy of the agents of our systems, this article focuses on how such
              ‘networks of devices’ interleave with the ‘network of humans’
              composed of the people visiting the installation or participating in the concert. Indeed, we postulate that an important point in understanding and describing such proposals is to
              consider the relation between these two networks
              , the way they co-exist and entangle themselves through perception and action. To exemplify these ideas, we present a number of case studies, sound installations and concert works, very different in scope and artistic goal, and examine how this interaction is materialised from several standpoints.},
	language = {en},
	number = {3},
	urldate = {2024-03-15},
	journal = {Organised Sound},
	author = {Bevilacqua, Frederic and Matuszewski, Benjamin and Paine, Garth and Schnell, Norbert},
	month = dec,
	year = {2021},
	pages = {333--339},
}

@book{blackwell_live_2022,
	title = {Live {Coding}: {A} {User}'s {Manual}},
	isbn = {978-0-262-37263-3},
	shorttitle = {Live {Coding}},
	url = {https://direct.mit.edu/books/book/5495/Live-CodingA-User-s-Manual},
	abstract = {The first comprehensive introduction to the origins, aspirations, and evolution of live coding.
            Performative, improvised, on the fly: live coding is about how people interact with the world and each other via code. In the last few decades, live coding has emerged as a dynamic creative practice, gaining attention across cultural and technical fields—from music and the visual arts to computer science. Live Coding: A User's Manual is the first comprehensive introduction to the practice and a broader cultural commentary on the potential for live coding to open up deeper questions about contemporary cultural production and computational culture. This multiauthored book—by artists and musicians, software designers, and researchers—provides a practice-focused account of the origins, aspirations, and evolution of live coding, including expositions from a wide range of live coding practitioners. In a more conceptual register, the authors consider liveness, temporality, and knowledge in relation to live coding, alongside speculating on the practice's future forms.
            To freely download and read ebook (mobi, epub) and PDF files, please visit the resources tab. This book is open access and can be freely downloaded, shared and (if you wish) edited, subject to a CC-BY-SA license.},
	language = {en},
	urldate = {2024-03-15},
	publisher = {The MIT Press},
	author = {Blackwell, Alan F. and Cocker, Emma and Cox, Geoff and McLean, Alex and Magnusson, Thor},
	month = nov,
	year = {2022},
	doi = {10.7551/mitpress/13770.001.0001},
	file = {Full Text:/Users/k.vasilakos/Zotero/storage/734XJ8BC/Blackwell et al. - 2022 - Live Coding A User's Manual.pdf:application/pdf},
}

@article{hodl_large-scale_2020,
	title = {Large-scale audience participation in live music using smartphones},
	volume = {49},
	issn = {0929-8215, 1744-5027},
	url = {https://www.tandfonline.com/doi/full/10.1080/09298215.2020.1722181},
	doi = {10.1080/09298215.2020.1722181},
	language = {en},
	number = {2},
	urldate = {2024-03-15},
	journal = {Journal of New Music Research},
	author = {Hödl, Oliver and Bartmann, Christoph and Kayali, Fares and Löw, Christian and Purgathofer, Peter},
	month = mar,
	year = {2020},
	pages = {192--207},
	file = {Full Text:/Users/k.vasilakos/Zotero/storage/VBKMG9GY/Hödl et al. - 2020 - Large-scale audience participation in live music u.pdf:application/pdf},
}

@inproceedings{vasilakos_konstantinos_2021,
	address = {Shanghai, China},
	title = {Konstantinos {Vasilakos} {Showcase} {Lick} {The} {Toad} {NIME} 2021},
	url = {https://nime.pubpub.org/pub/lick-the-toad-konvas-nime2021},
	doi = {10.21428/92fbeb44.974a1648},
	urldate = {2024-03-15},
	booktitle = {{NIME} 2021},
	publisher = {PubPub},
	author = {Vasilakos, Konstantinos},
	month = jun,
	year = {2021},
	file = {Full Text:/Users/k.vasilakos/Zotero/storage/PYB29RTH/Vasilakos - 2021 - Konstantinos Vasilakos Showcase Lick The Toad NIME.pdf:application/pdf},
}

@article{vasilakos_networked_2022,
	title = {A {Networked} {Hybrid} {Interface} for {Audience} {Sonification} and {Machine} {Learning}},
	volume = {10},
	issn = {2317-9937},
	url = {https://periodicos.unespar.edu.br/index.php/vortex/article/view/4695},
	doi = {10.33871/23179937.2022.10.1.4695},
	abstract = {Lick the Toad is an ongoing project developed as a web based interface that runs in modern browsers. It provides a custom made platform to collect user data accessed from mobile devices, such as smartphones, tablets etc. The system offers a tool for interactive collective sonification supporting networked music performance. It can be used in various contexts, such as an onsite installation, or for the distribution of raw data for live coding performances making it a versatile component for an array of creative practices. Of these, live coding which is one of the author's artistic approach to create live performances is demonstrated in this article highlighting and elaborating on technical and musical aspects of this approach. Final sections outline the system as a tool for live coding performances and cover a series of potential interactions integrating audience and/or using it independently alike.},
	number = {1},
	urldate = {2024-03-15},
	journal = {Revista Vórtex},
	author = {Vasilakos, Konstantinos},
	month = apr,
	year = {2022},
}

@inproceedings{xambo_performing_2020,
	address = {Birmingham, UK},
	title = {Performing {Audiences}: {Composition} {Strategies} for {Network} {Music} using {Mobile} {Phones}},
	url = {https://annaxambo.me/pub/Xambo_Roma_2020_Performing_Audiences.pdf},
	abstract = {With the development of web audio standards, it has quickly become technically easy to develop and deploy software for inviting audiences to participate in musical performances using their mobile phones. Thus, a new audience-centric musical genre has emerged, which aligns with artistic manifestations where there is an explicit inclusion of the public (e.g. participatory art, cinema or theatre). Previous research has focused on analysing this new genre from historical, social organisation and technical perspectives. This follow-up paper contributes with reﬂections on technical and aesthetic aspects of composing within this audience-centric approach. We propose a set of 13 composition dimensions that deal with the role of the performer, the role of the audience, the location of sound and the type of feedback, among others. From a reﬂective approach, four participatory pieces developed by the authors are analysed using the proposed dimensions. Finally, we discuss a set of recommendations and challenges for the composers-developers of this new and promising musical genre. This paper concludes discussing the implications of this research for the NIME community.},
	language = {en},
	booktitle = {Proceedings of the {New} {Interfaces} for {Musical} {Expression} ({NIME} ’20)},
	author = {Xambó, Anna and Roma, Gerard},
	year = {2020},
	pages = {55--60},
	file = {Xambó and Roma - Performing Audiences Composition Strategies for N.pdf:/Users/k.vasilakos/Zotero/storage/65BCZDIT/Xambó and Roma - Performing Audiences Composition Strategies for N.pdf:application/pdf},
}

@article{vasilakos_exploring_2021,
	title = {{EXPLORING} {LIVE} {CODING} {AS} {PERFORMANCE} {PRACTICE}},
	volume = {21},
	url = {https://dergipark.org.tr/en/download/article-file/2120799},
	abstract = {Live coding is the dynamic process of modifying the source code of a running software that generates sound or visuals (Collins, 2011; Collins et al., 2003; Collins \& Escrivan Rincón, 2011; Nilson, 2007). It is an emerging laptop performance paradigm that is used in many art scenes and research practices in the digital arts and contemporary musical scenes, such as Computer Music, Electroacoustic performance and the broad landscape of Sonic/Sound Art, as well as in the Algorave community, a live music idiom broadly referring to the creation of dance music using live coding to hack music which interacts with visuals. In the context of Electroacoustic music, it provides an ideal interface for experimentation as it allows one to improvise the structure of algorithms that constitute the sound synthesis engine of a computer-based musical environment, and thus releases the performer from constraints and limitations from fixed interaction possibilities. This not only relates on the interactivity capabilities of a digital system, but also has a great impact on the higher level musical characteristics of a composition, as opposed to other paradigms of live electronic music. This artistic practice, enacted by the technical act of programming, is deployed by the coder/performer as a means to create indeterministic sonic manipulations informed by his/her aesthetic musical decisions during improvisation. Interestingly, live coding also contributes to the question of causality in the performance of electronic music. One can argue that live coding addresses this issue by inviting the audience to engage in the live process via visualizing the alteration of the structure of the code in real time, enhancing the sense of liveness during improvisation. While live coding merely indicates the techne of devising sound algorithms “on the fly,” it spans many diverse ecosystems in a live electronic music landscape. Live coding also heralds the emergence of dedicated artistic communities, such as the Algorave and Toplap2 organization, referred as the “home of live coding”. Toplap hosts new findings and projects, while a dedicated conference named International Conference on Live Coding is inviting new research internationally, highlighting new tools and practices in the field. The author will report his own research in the field of live coding, reflecting on two personal ongoing projects: the Istanbul Coding Ensemble (ICE), a laptop ensemble working in the field of dynamic programming and improvisation using networked music systems, and an Algorave3 side project given the alias Chunk No\_Reace.},
	language = {en},
	urldate = {2024-03-25},
	author = {Vasilakos, Konstantinos},
	year = {2021},
	pages = {21--38},
	file = {Vasilakos - EXPLORING LIVE CODING AS PERFORMANCE PRACTICE.pdf:/Users/k.vasilakos/Zotero/storage/JN25LVQQ/Vasilakos - EXPLORING LIVE CODING AS PERFORMANCE PRACTICE.pdf:application/pdf},
}

@inproceedings{vasilakos_sonication_2020,
	address = {Birmingham, UK},
	title = {Soniﬁcation of {High} {Energy} {Physics} {Data} {Using} {Live} {Coding} and {Web} {Based} {Interfaces}},
	url = {https://www.nime.org/proceedings/2020/nime2020_paper76.pdf},
	abstract = {This paper presents a discussion of Dark Matter, a soniﬁcation project by the Birmingham Ensemble for Electroacoustic Research (BEER), a laptop group using live coding and just-in-time programming techniques, based at the University of Birmingham (UK). The project uses prerecorded data from proton-proton collisions produced by the Large Hadron Collider (LHC) at CERN, Switzerland, and then detected and reconstructed by the Compact Muon Solenoid (CMS) experiment, and was developed with the support of the art@CMS project. Work for the Dark Matter project included the development of a custom-made environment in the SuperCollider (SC) programming language that lets the performers of the group engage in collective improvisations using dynamic interventions and networked music systems. This paper will also provide information about a spin-oﬀ project entitled the Interactive Physics Soniﬁcation System (IPSOS), an interactive and standalone online application developed in the JavaScript programming language. It provides a web-based interface that allows users to map particle data to sound on commonly used web browsers, and mobile devices, such as smartphones, tablets etc. The project was developed as an educational outreach tool to engage young students and the general public with prerecorded data derived from LHC collisions.},
	language = {en},
	urldate = {2024-03-25},
	booktitle = {Proceedings of the {International} {Conference} on {New} {Interfaces} for {Musical} {Expression}},
	author = {Vasilakos, Konstantinos and Wilson, Scott and McCauley, Thomas and Khosravi, Milad and Margetson, Emma and Yeung, Tsun Winston},
	year = {2020},
	pages = {388--393},
	file = {Vasilakos et al. - Soniﬁcation of High Energy Physics Data Using Live.pdf:/Users/k.vasilakos/Zotero/storage/RZYH64B6/Vasilakos et al. - Soniﬁcation of High Energy Physics Data Using Live.pdf:application/pdf},
}

@article{vasilakos_exploring_nodate,
	title = {{EXPLORING} {LIVE} {CODING} {AS} {PERFORMANCE} {PRACTICE}},
	abstract = {Live coding is the dynamic process of modifying the source code of a running software that generates sound or visuals (Collins, 2011; Collins et al., 2003; Collins \& Escrivan Rincón, 2011; Nilson, 2007). It is an emerging laptop performance paradigm that is used in many art scenes and research practices in the digital arts and contemporary musical scenes, such as Computer Music, Electroacoustic performance and the broad landscape of Sonic/Sound Art, as well as in the Algorave community, a live music idiom broadly referring to the creation of dance music using live coding to hack music which interacts with visuals. In the context of Electroacoustic music, it provides an ideal interface for experimentation as it allows one to improvise the structure of algorithms that constitute the sound synthesis engine of a computer-based musical environment, and thus releases the performer from constraints and limitations from fixed interaction possibilities. This not only relates on the interactivity capabilities of a digital system, but also has a great impact on the higher level musical characteristics of a composition, as opposed to other paradigms of live electronic music. This artistic practice, enacted by the technical act of programming, is deployed by the coder/performer as a means to create indeterministic sonic manipulations informed by his/her aesthetic musical decisions during improvisation. Interestingly, live coding also contributes to the question of causality in the performance of electronic music. One can argue that live coding addresses this issue by inviting the audience to engage in the live process via visualizing the alteration of the structure of the code in real time, enhancing the sense of liveness during improvisation. While live coding merely indicates the techne of devising sound algorithms “on the fly,” it spans many diverse ecosystems in a live electronic music landscape. Live coding also heralds the emergence of dedicated artistic communities, such as the Algorave and Toplap2 organization, referred as the “home of live coding”. Toplap hosts new findings and projects, while a dedicated conference named International Conference on Live Coding is inviting new research internationally, highlighting new tools and practices in the field. The author will report his own research in the field of live coding, reflecting on two personal ongoing projects: the Istanbul Coding Ensemble (ICE), a laptop ensemble working in the field of dynamic programming and improvisation using networked music systems, and an Algorave3 side project given the alias Chunk No\_Reace.},
	language = {en},
	author = {Vasilakos, Konstantinos},
	file = {Vasilakos - EXPLORING LIVE CODING AS PERFORMANCE PRACTICE.pdf:/Users/k.vasilakos/Zotero/storage/KVAIUX78/Vasilakos - EXPLORING LIVE CODING AS PERFORMANCE PRACTICE.pdf:application/pdf},
}

@article{vasilakos_networked_2022-1,
	title = {A {Networked} {Hybrid} {Interface} for {Audience} {Sonification} and {Machine} {Learning}},
	volume = {10},
	issn = {2317-9937},
	url = {https://periodicos.unespar.edu.br/index.php/vortex/article/view/4695},
	doi = {10.33871/23179937.2022.10.1.4695},
	abstract = {Lick the Toad is an ongoing project developed as a web based interface that runs in modern browsers. It provides a custom made platform to collect user data accessed from mobile devices, such as smartphones, tablets etc. The system offers a tool for interactive collective sonification supporting networked music performance. It can be used in various contexts, such as an onsite installation, or for the distribution of raw data for live coding performances making it a versatile component for an array of creative practices. Of these, live coding which is one of the author's artistic approach to create live performances is demonstrated in this article highlighting and elaborating on technical and musical aspects of this approach. Final sections outline the system as a tool for live coding performances and cover a series of potential interactions integrating audience and/or using it independently alike.},
	number = {1},
	urldate = {2024-03-25},
	journal = {Revista Vórtex},
	author = {Vasilakos, Konstantinos},
	month = apr,
	year = {2022},
	file = {Full Text:/Users/k.vasilakos/Zotero/storage/QAQYVB9L/Vasilakos - 2022 - A Networked Hybrid Interface for Audience Sonifica.pdf:application/pdf},
}

@article{christopher_kontrol_nodate,
	title = {Kontrol: {Hand} {Gesture} {Recognition} for {Music} and {Dance} {Interaction}},
	abstract = {This paper describes Kontrol, a new hand interface that extends the intuitive control of electronic music to traditional instrumentalist and dancers. The goal of the authors has been to provide users with a device that is capable of detecting the highly intricate and expressive gestures of the master performer, in order for that information to be interpreted and used for control of electronic music. This paper discusses related devices, the architecture of Kontrol, its potential as a gesture recognition device, and several performance applications.},
	language = {en},
	author = {Christopher, Kameron and He, Jingyin and Kapur, Raakhi Sinha and Kapur, Ajay},
	file = {Christopher et al. - Kontrol Hand Gesture Recognition for Music and Da.pdf:/Users/k.vasilakos/Zotero/storage/V9TV9J3G/Christopher et al. - Kontrol Hand Gesture Recognition for Music and Da.pdf:application/pdf},
}

@article{christopher_kontrol_2013-1,
	title = {Kontrol: {Hand} {Gesture} {Recognition} {For} {Music} {And} {Dance} {Interaction}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	shorttitle = {Kontrol},
	url = {https://zenodo.org/record/1178495},
	doi = {10.5281/ZENODO.1178495},
	abstract = {This paper describes Kontrol, a new hand interface that extends the intuitivecontrol of electronic music to traditional instrumentalist and dancers. Thegoal of the authors has been to provide users with a device that is capable ofdetecting the highly intricate and expressive gestures of the master performer,in order for that information to be interpreted and used for control ofelectronic music. This paper discusses related devices, the architecture ofKontrol, it's potential as a gesture recognition device, and severalperformance applications.},
	urldate = {2024-03-25},
	author = {Christopher, Kameron and He, Jingyin and Kapur, Raakhi and Kapur, Ajay},
	month = jun,
	year = {2013},
	note = {Publisher: [object Object]},
}

@article{he_developing_2015-1,
	title = {Developing {A} {Physical} {Gesture} {Acquisition} {System} {For} {Guqin} {Performance}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	url = {https://zenodo.org/record/1179087},
	doi = {10.5281/ZENODO.1179087},
	abstract = {Motion- based musical interfaces are ubiquitous. With the plethora of sensing solutions and the possibility of developing custom designs, it is important that the new musical interface has the capability to perform any number of tasks. This paper presents the theoretical framework for defining, designing, and evaluation process of a physical gesture acquisition for Guqin performance. The framework is based on an iterative design process, and draws upon the knowledge in Guqin performance to develop a system to determine the interaction between a Guqin player and the computer. This paper emphasizes the definition, conception, and evaluation of the acquisition system.},
	urldate = {2024-03-25},
	author = {He, Jingyin and Kapur, Ajay and Carnegie, Dale},
	month = jun,
	year = {2015},
	note = {Publisher: [object Object]},
}

@article{ho_slowqin_2019-1,
	title = {The {SlowQin}: {An} {Interdisciplinary} {Approach} to reinventing the {Guqin}},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	shorttitle = {The {SlowQin}},
	url = {https://zenodo.org/record/3672947},
	doi = {10.5281/ZENODO.3672947},
	abstract = {This paper presents an ongoing process of examining and reinventing the Guqin, to forge a contemporary engagement with this unique traditional Chinese string instrument. The SlowQin is both a hybrid resemblance of the Guqin and a fully functioning wireless interface to interact with computer software. It has been developed and performed during the last decade. Instead of aiming for virtuosic perfection of playing the instrument, SlowQin emphasizes the openness for continuously rethinking and reinventing the Guqin's possibilities. Through a combination of conceptual work and practical production, Echo Ho's SlowQin project works as an experimental twist on Historically Informed Performance, with the motivation of conveying artistic gestures that tackle philosophical, ideological, and socio-political subjects embedded in our living environment in globalised conditions. In particular, this paper touches the history of the Guqin, gives an overview of the technical design concepts of the instrument, and discusses the aesthetical approaches of the SlowQin performances that have been realised so far.},
	urldate = {2024-03-25},
	author = {Ho, Echo and de Campo, Prof. Dr. Phil. Alberto and Hoelzl, Hannes},
	month = jun,
	year = {2019},
	note = {Publisher: [object Object]},
}

@inproceedings{vasilakos_lick_2021,
	address = {Brasil},
	title = {Lick the {Toad}: a web-based interface for collective sonification},
	shorttitle = {Lick the {Toad}},
	url = {https://sol.sbc.org.br/index.php/sbcm/article/view/19444},
	doi = {10.5753/sbcm.2021.19444},
	abstract = {Lick the Toad is an ongoing project developed as a web based interface that runs in modern browsers. It provides a custom made platform to collect user data accessed from mobile devices, such as smartphones, tablets etc. The system offers a tool for interactive collective sonification aiding the idea of networked music performance. It can be used in various contexts, such as onsite installation, interactive compositional tool, or for the distribution of raw data for live coding performances. The system embeds neural network capabilities for prediction purposes by using user input and outputs/targets alike. The inputs and the targets of the training processes can be adapted according to the needs of the use making it a versatile component for creative practice. It is developed as open-source project and it works currently as a NodeJS application with plans for future deployment on remote server to support remote communication and interaction amongst distant users.},
	urldate = {2024-04-10},
	booktitle = {Anais do {XVIII} {Simpósio} {Brasileiro} de {Computação} {Musical} ({SBCM} 2021)},
	publisher = {Sociedade Brasileira de Computação - SBC},
	author = {Vasilakos, Konstantinos},
	month = oct,
	year = {2021},
	pages = {178--188},
	file = {Full Text:/Users/k.vasilakos/Zotero/storage/ZN73P7QR/Vasilakos - 2021 - Lick the Toad a web-based interface for collectiv.pdf:application/pdf},
}

@misc{crab_musical_2024,
	type = {Blog},
	title = {The ‘{Musical} {Telegraph}’ or ‘{Electro}-{Harmonic} {Telegraph}’, {Elisha} {Gray}. {USA}, 1874},
	shorttitle = {120 {Years} of {Electronic} {Music}},
	url = {https://120years.net/the-musical-telegraphelisha-greyusa1876/},
	language = {en},
	urldate = {2024-05-25},
	journal = {120 Years of Electronic Music: The history of electronic musical instruments from 1800 to 2019},
	author = {Crab},
	month = may,
	year = {2024},
}

@inproceedings{vasilakos_exploring_2024,
	address = {Arenzano, Genoa Italy},
	title = {Exploring {Sonic} {Frontiers} using {Lick}-the-{Toad} ({LTT})},
	isbn = {9798400717642},
	url = {https://dl.acm.org/doi/10.1145/3656650.3656653},
	doi = {10.1145/3656650.3656653},
	language = {en},
	urldate = {2024-06-05},
	booktitle = {Proceedings of the 2024 {International} {Conference} on {Advanced} {Visual} {Interfaces}},
	publisher = {ACM},
	author = {Vasilakos, Konstantinos},
	month = jun,
	year = {2024},
	pages = {1--3},
}

@inproceedings{vasilakos_lick_2024,
	title = {From {Lick} the {Toad} to {Craft} the {Code}},
	copyright = {Creative Commons Attribution 4.0 International},
	url = {https://zenodo.org/doi/10.5281/zenodo.11350311},
	doi = {10.5281/ZENODO.11350311},
	abstract = {As in the era of Ars Nova which provided the platform for composers’ exploration of rhythmical representation, (mobile) technology-mediated audience participation is now baby booming due to the rapid discourse of the web-based technologies open to any layman who is interested in the field of innovative music-making. Expanding on the main focus of this paper, that is, technology mediated audience interaction during live coding, networked capabilities in music systems can provide the means for realizing projects that empower audience interaction in live coding performances. Lick the Toad is a custom-made system developed using web technologies and it was built to provide a platform for interaction between members of the audience and performer(s) enabling an ongoing dialogue between individual sound nodes generated by users’ devices and live coders as a means to govern the decisions of the coding procedure. To enhance variability of sonic events amongst the users the system uses a neural network model trained using input generated by the users. This is a ready-to-use sound-making interface that can generate sound out of the box while engaging in a bidirectional communication using Open Sound Control (OSC) messages that are shared to an accompanying live coding interface environment built in SuperCollider for this purpose. A demonstration of the project and its creative outputs are provided in the paper as well as an analysis of a musical performance which was created using this system.},
	urldate = {2024-06-05},
	author = {Vasilakos, Konstantinos},
	month = may,
	year = {2024},
	note = {Publisher: Zenodo},
	keywords = {audience participation, live coding, networked music},
}

@misc{vasilakos_shanghaiff_nodate,
	address = {ICLC, Shanghai, PRC},
	type = {Performance},
	title = {{ShanghaiFF}\#\# {A} {Live} {Coding}: {Audio}-{Visual} {Performance}},
	url = {https://iclc.toplap.org/2024/program/13.html},
	urldate = {2024-07-06},
	author = {Vasilakos, Konstantinos},
	month = jun,
}
